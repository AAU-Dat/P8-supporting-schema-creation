
\section{preliminaries}\label{sec:preliminaries}

\subsection{Lattices}\label{subsec:lattices}
This section contains the definitions and theorems of lattices, complete lattices, and partial orders.
These definitions are necessary to understand the theory behind abstract interpretation.\cite{nielson_formal_2019}


\begin{definition}
    A \textit{partial order} $(S, \sqsubseteq)$ is set $S$ equipped with a binary relation $\sqsubseteq$ that is reflexive, transitive and antisymmetric.
\end{definition}


For $X \sqsubseteq S$ and $y \in S$ we take


\begin{equation*}
    X \sqsubseteq y \iff \forall x \in X : x \sqsubseteq y,
\end{equation*}


and analogous for $y \sqsubseteq X$.


\begin{definition}
    A \textit{complete lattice} $(S, \sqsubseteq, \sqcup, \sqcap)$ is a partial order $(S, \sqsubseteq)$ in which for all $X \subseteq S:$ $\bigsqcup X$ and $\bigsqcap X$ are defined,
        \begin{equation*}
            X \sqsubseteq \bigsqcup X \land \forall y \in S : X \sqsubseteq y \implies \bigsqcup X \sqsubseteq y,
        \end{equation*}
        and
        \begin{equation*}
            \bigsqcap X \sqsubseteq X \land \forall y \in S : y \sqsubseteq X \implies y \sqsubseteq \bigsqcap X.
        \end{equation*}
\end{definition}


As a shorthand we take $x \sqcup y = \bigsqcup \{x, y\}$ and $x \sqcap y = \bigsqcap \{x, y\}$.


\begin{definition}
    A \textit{lattice} $(S, \sqsubseteq, \sqcup, \sqcap)$ is a partial order $(S, \sqsubseteq)$ in which for all $x,y \in S:$ $x \sqcup y$ and $x \sqcap y$ are defined,
        \begin{equation*}
            \{x, y\} \sqsubseteq x \sqcup y \land \forall z \in S : \{x, y\} \sqsubseteq z \implies x \sqcup y \sqsubseteq z,
        \end{equation*}
        and
        \begin{equation*}
            x \sqcap y \sqsubseteq \{x, y\} \land \forall z \in S : z \sqsubseteq \{x, y\} \implies z \sqsubseteq x \sqcap y.
        \end{equation*}
\end{definition}


\begin{theorem}\label{thm:kleene_finite}
    In a complete lattice $L$ with finite height, every monotone function $f : L \rightarrow L$ has a unique fixed point
    \begin{equation*}
        lfp(f) = \bigsqcup\{f^n(\perp) \mid n \in \mathbb{N}\}
    \end{equation*}.
\end{theorem}


\begin{theorem}\label{thm:kleene_scott}
    In a complete lattice $L$, every Scott-continuous function $f : L \rightarrow L$ has a unique fixed point $lfp(f)$.
\end{theorem}


\begin{theorem}
    If $L_1, L_2, \dots, L_n$ are complete lattices, the so is the product:
    \begin{equation*}
        L_1 \times L_2 \times \dots L_n = \{(x_1, x_2, \dots x_n) \mid x_i \in L_i\}
    \end{equation*}

    where the order $\sqsubseteq$ is defined component-wise:

    \begin{align*}
        \begin{split}
        (x_1, x_2, \dots, x_n) &\sqsubseteq (x_1', x_2', \dots, x_n') \\
        \iff
        \forall i &= 1, 2, \dots n : x_i \sqsubseteq x_i'
        \end{split}
    \end{align*}
\end{theorem}

\begin{theorem}
    If $A$ is a set and $L$ a complete lattice, then $L^A$ is a complete lattice when
    \begin{equation}
        f \sqsubseteq g \iff \forall a \in A : f(a) \sqsubseteq g(a) \text{ where } f,g \in L^A.\label{eq:equation-complete-lattice-theorem}
    \end{equation}

\end{theorem}

\todo[inline]{
    Casper says:
    The four theorems above should have a source.
}

\subsection{Abstract Interpretation}\label{subsec:abstract-interpretation}

Here we give a quick presentation abstract interpretation.
The presentation is heavily based on \cite{nielson_formal_2019} with some additions from \cite{moller_statitc_nodate}.
As the presentation is rudimentary we encourage the reader to review \cite{noauthor_abstract_nodate} or \cite{cousot_abstract_1996} for a informal introduction of the subject, and the respective chapters in \cite{nielson_formal_2019} and \cite{moller_statitc_nodate} for a more complete explanation or \cite{cousot_abstract_1977} for the seminal work.

First we define two central notions, namely soundness and valid analysis assignments.

\begin{definition}
    Given a set $\rho \in \mathfrak{E}$ of possible concrete program memories, and a set $\ab{\rho} \in \ab{\mathfrak{E}}$ of possible abstract program memories, related by a concretization function $\gamma : \mathcal{P}(\ab{\mathfrak{E}}) \rightarrow \mathcal{P}(\mathfrak{E})$.
    A concrete semantic over program instructs $I \in \mathbb{I}$, $\sem{\cdot} : \mathbb{I} \rightarrow \mathfrak{E} \rightarrow \mathfrak{E}$ and an abstract semantic $\abssem{\cdot} : \mathbb{I} \rightarrow \mathcal{P}(\ab{\mathfrak{E}}) \rightarrow \mathcal{P}(\ab{\mathfrak{E}})$, $\abssem{\cdot}$ is said to be \emph{sound} whenever:
    \begin{equation}
        \rho \in \concrete(\ab{E}) \land \sem{I}(m) = m' \implies m' \in \concrete(\abssem{I}(\ab{E}))
    \end{equation}
\end{definition}

\begin{definition}\label{def:valid}
    Given a program graph with vertices $Q$ and edges $E$, an assignment $A : Q \rightarrow \mathcal{P}(\ab{\mathfrak{E}})$, that assignment is said to be \emph{valid} if its the case that:
    \begin{itemize}
        \item If $q_\circ \xrightarrow{I} q_\bullet \in E$ then $\abssem{I}(A(q_\circ)) \subseteq A(q_\bullet)$,
        \item and $\ab{E}_\triangleright \subseteq A(q_\triangleright)$, where $q_\triangleright$ is the initial program point in the program graph and $\ab{E}_\triangleright$ is a set of abstract memories that hold initially in the initial state.
    \end{itemize}
\end{definition}

Given the previously two definitions, if the initial abstract memories for the initial program point $\ab{E}_\triangleright$ is set such that $E_{\triangleright} \subseteq \concrete(\ab{E}_\triangleright)$, for concrete memories holding initially $E_{\triangleright}$ in the initial program point, the abstract semantics are sound and the analysis assignment is valid, then it can be shown that if $\rho \in \concrete(A(q_\circ))$ and $\langle q_\circ; \rho \rangle \xRightarrow{\omega^\star} \langle q_\bullet; \rho' \rangle$ then $\rho' \in \concrete(A(q_\bullet))$.
What that intuitively means is that the analysis assignment is a safe over approximation of the actual state-space of the program.
Valid analysis assignment can then readily be computed as explained in \cite{nielson_formal_2019}.

\begin{theorem}\label{thm:galoispre}
    For $\gamma : L_1 \rightarrow L_2$ where $L_1$ and $L_2$ are complete lattices there exist a function $\alpha : L_2 \rightarrow L_1$ such that $\alpha$ and $\gamma$ forms a Galois connection if $\gamma\left(\bigsqcap B\right) = \bigsqcap_{b \in B}\gamma(b)$ for every $B \subseteq L_1$.
\end{theorem}

\subsection{Converting Code Program Graph}\label{subsec:converting-code-program-graph}
This section will briefly cover how the program graph is created.
Creating a program graph from the code is already a proven concept.
Therefore, this paper will not delve into the details but inform the reader.
The book used to show that the concept of creating a program graph from code is a proven concept is~\cite[see][chap 2.2]{nielson_formal_2019}.
A program graph consists of a finite set of nodes, initial and final nodes, actions, and edges.

These directed edges represent the program's flow, and the nodes represent its state.
The edges' actions are the atomic operations that the program can perform.
The initial node is the program's starting point, and the final node is the program's end.

The program graph is created by parsing the code and creating nodes and edges that represent the flow of the code.
This process, while it may sound complex, is relatively straightforward.
For instance, if the code is only an assignment of a variable, there will be a node for the initial state before the variable is assigned, a node for the final state after the variable is assigned, and an edge between them that represents the action of the assignment.
This is written as the following equation:
$edges(q_{\circ} \rightsquigarrow q_{\bullet})\llbracket x \coloneqq a \rrbracket = \{(q_{\circ}, x \coloneqq a, q_{\bullet})\}$
$q_{\circ}$ is the initial node, $q_{\bullet}$ is the final node, and $x \coloneqq a$ is the assignment.

This creates a set that represents the program graph, which can be seen in \autoref{fig:tikz-program-graph-assignment}.
This is a simple example, and the program graph can be more complex depending on the code, but the concept is the same.
Further examples can be found in~\cite[Figure 2.6]{nielson_formal_2019}.

\begin{figure}[htb!]
    \center
    \input{figures/program-graph}
    \caption{An example that shows a program graph of an assignment}
    \label{fig:tikz-program-graph-assignment}
\end{figure}

We later describe the abstract syntax; \autoref{fig:abstract-syntax-instructions} describes the instructions the abstract syntax will contain.
There is no control structure in the abstract syntax, like if-statements and loops or sequences of instructions.
This is because the abstract syntax is simplified to make understanding the theory behind abstract interpretation easier.
This is all handled in the program graph, where the control structure is represented as edges in the program graph.

\begin{figure}
    \center
    \begin{tabular}{r l}
        $I \Coloneqq$ & $skip \mid v_a \coloneqq e \mid v_a \coloneqq ? \mid C_{sql} \mid b$
    \end{tabular}
    \caption{Abstract Syntax for Instructions}
    \label{fig:abstract-syntax-instructions}
\end{figure}

If-statements and loops are still used as boolean expressions in edges, used like guards in the program graph.
We can make equations for the edges of the program graph, where $b$ is a Boolean expression, and $S$ is a set of states done in the control structure.

$edges(q_{\circ} \rightsquigarrow q_{\bullet})\llbracket \text{if } b \text{ then } S_1 \text{ else } S_2 \rrbracket = \text{let } q_{cond}$ be a new node.
\begin{align}
S_{cond} &= edges(q_\circ \rightsquigarrow q_{cond})\llbracket b \rrbracket \\
S_{true} &= edges(q_{cond} \rightsquigarrow q_{\bullet})\llbracket S_1 \rrbracket \\
    S_{false} &= edges(q_{cond} \rightsquigarrow q_{\bullet})\llbracket S_2 \rrbracket \\
    &\text{in } S_{cond} \cup S_{true} \cup S_{false}
\end{align}

$edges(q_{\circ} \rightsquigarrow q_{\bullet})\llbracket \text{while } b \text{ do } I\rrbracket= \text{let } q_{cond}$ be a new node,
\begin{align}
    S_{cond} &= edges(q_\circ \rightsquigarrow q_{cond}) \llbracket b \rrbracket \\
    S_{body}&=edges(q_{cond} \rightsquigarrow q_{body})\llbracket I \rrbracket \\
    S_{loop} &= edges(q_{body} \rightsquigarrow q_{cond})\llbracket\text{true}\rrbracket \\
    S_{exit} &= edges(q_{cond} \rightsquigarrow q_{\bullet})\llbracket\text{false}\rrbracket \\
    &\text{in } S_{cond} \cup S_{body} \cup S_{loop} \cup S_{exit}
\end{align}

In \autoref{fig:tikz-program-graph-loop} and \autoref{fig:tikz-program-graph-if}, we see examples of how a loop and an if-statement are represented in a program graph.

\begin{figure}[htb!]
    \center
    \input{figures/if_graph}
    \caption{An example that shows a program graph of an if-statement}
    \label{fig:tikz-program-graph-if}
\end{figure}

\begin{figure}[htb!]
    \center
    \input{figures/loop_graph}
    \caption{An example that shows a program graph of a loop}
    \label{fig:tikz-program-graph-loop}
\end{figure}

In the abstract syntax, we will not have formulated sequences of $I_0, I_1, I_2, \dots, I_n$ as in the program graph, but rather as a set of states $S$, where we at the end go back to the initial state, this is shown in \autoref{fig:tikz-composition-graph}.

We can make equations for the edges of the composition graph, where $I_1$ and $I_2$ are instructions.
$edges(q_{\circ} \rightsquigarrow q_{\bullet})\llbracket I_1 ; I_2 \rrbracket = \text{let q be a new node}$
\begin{align}
S_1 &= edges(q_{\circ} \rightsquigarrow q)\llbracket I_1 \rrbracket\\
S_2 &= edges(q \rightsquigarrow q_{\bullet})\llbracket I_2 \rrbracket, \\
&\text{ in } S_1 \cup S_2
\end{align}

\begin{figure}
    \center
    \input{figures/composition_graph}
    \caption{An example that shows a composition graph}
    \label{fig:tikz-composition-graph}
\end{figure}
